{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlQAX9lVvNoVa6fvzJJ0ty",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DaniOsuna/Trading_Model_Script/blob/main/Copia_de_Trading_Model_Script_Maestro_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# SCRIPT MAESTRO 14 - Descarga CSV de CryptoDataDownload + Clasificación LSTM\n",
        "# Ajustado para renombrar \"Volume BTC\"/\"Volume USDT\" a \"Volume\"\n",
        "################################################################################\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install pandas_ta requests\n",
        "\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pandas_ta as ta\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "import requests\n",
        "import time\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "print(\"=== INICIO DEL SCRIPT MAESTRO 13 (Descarga CSV + Clasificación) ===\")\n",
        "\n",
        "############################\n",
        "# 1) PARÁMETROS\n",
        "############################\n",
        "CSV_URL  = \"https://www.cryptodatadownload.com/cdd/Binance_BTCUSDT_d.csv\"  # Ejemplo\n",
        "LOCAL_CSV = \"/content/drive/MyDrive/Binance_BTCUSDT_daily.csv\"\n",
        "\n",
        "THRESHOLD_GAIN= 0.003\n",
        "WINDOW        = 30\n",
        "STOP_LOSS     = 0.02\n",
        "TAKE_PROFIT   = 0.03\n",
        "COMMISSION    = 0.001\n",
        "TEST_DAYS     = 60\n",
        "LR            = 1e-4\n",
        "BATCH_SIZE    = 32\n",
        "EPOCHS        = 20\n",
        "\n",
        "SAVE_TRADES_CSV = \"/content/drive/MyDrive/Trading_Optimization_LSTM/paper_trades_binaria_diaria.csv\"\n",
        "\n",
        "############################\n",
        "# 2) Descargar CSV\n",
        "############################\n",
        "def download_csv_from_cryptodatadownload(url, local_path):\n",
        "    max_retries=3\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            print(f\"Descargando CSV desde: {url}\")\n",
        "            r= requests.get(url, timeout=30)\n",
        "            if r.status_code==200:\n",
        "                with open(local_path, 'wb') as f:\n",
        "                    f.write(r.content)\n",
        "                print(f\"Guardado => {local_path}\")\n",
        "                return True\n",
        "            else:\n",
        "                print(f\"Error HTTP: {r.status_code}. Reintento en 60s...\")\n",
        "                time.sleep(60)\n",
        "        except Exception as e:\n",
        "            print(f\"Excepcion: {e}. Reintento en 60s...\")\n",
        "            time.sleep(60)\n",
        "    return False\n",
        "\n",
        "############################\n",
        "# 3) Weighted BCE\n",
        "############################\n",
        "def weighted_bce(y_true, y_pred):\n",
        "    import tensorflow as tf\n",
        "    from tensorflow.keras.backend import epsilon\n",
        "    weight_for_1 = 3.0\n",
        "    y_true_f = tf.cast(y_true, tf.float32)\n",
        "    y_pred_f = tf.clip_by_value(y_pred, epsilon(), 1.0 - epsilon())\n",
        "    w0 = 1.0\n",
        "    w1 = weight_for_1\n",
        "    bce = - ( w1*y_true_f*tf.math.log(y_pred_f) + w0*(1.0-y_true_f)*tf.math.log(1.0-y_pred_f) )\n",
        "    return tf.reduce_mean(bce)\n",
        "\n",
        "############################\n",
        "# 4) BACKTEST BINARIO\n",
        "############################\n",
        "def backtest_binario(df_test, stop_loss=0.02, take_profit=0.03, commission=0.001):\n",
        "    pnl_list=[]\n",
        "    in_position=False\n",
        "    open_price=None\n",
        "    daily_ret=[]\n",
        "    for i in range(len(df_test)-1):\n",
        "        row= df_test.iloc[i]\n",
        "        if not in_position:\n",
        "            if row['y_pred_bin']==1:\n",
        "                open_price= row['OpenShift']\n",
        "                in_position=True\n",
        "                pnl_list.append(0.0)\n",
        "                daily_ret.append(0.0)\n",
        "            else:\n",
        "                pnl_list.append(0.0)\n",
        "                daily_ret.append(0.0)\n",
        "        else:\n",
        "            current_price= row['OpenShift']\n",
        "            lat_gain= (current_price - open_price)/open_price\n",
        "            close_trade=False\n",
        "            if lat_gain<= -stop_loss: close_trade=True\n",
        "            if lat_gain>= take_profit: close_trade=True\n",
        "            if row['y_pred_bin']==0: close_trade=True\n",
        "            if close_trade:\n",
        "                final_gain= lat_gain - 2*commission\n",
        "                pnl_list.append(final_gain)\n",
        "                daily_ret.append(final_gain)\n",
        "                in_position=False\n",
        "                open_price=None\n",
        "            else:\n",
        "                pnl_list.append(0.0)\n",
        "                daily_ret.append(0.0)\n",
        "    pnl_list.append(0.0)\n",
        "    daily_ret.append(0.0)\n",
        "    df_test['PnL']= pnl_list\n",
        "    df_test['CumPnL']= (1+df_test['PnL']).cumprod()-1\n",
        "    return df_test, daily_ret\n",
        "\n",
        "############################\n",
        "# 5) METRICAS\n",
        "############################\n",
        "def calc_metrics(daily_ret):\n",
        "    import pandas as pd\n",
        "    rets= pd.Series(daily_ret)\n",
        "    if len(rets)<1:\n",
        "        return (0,0,0,0)\n",
        "    cumret= (1+ rets).cumprod()-1\n",
        "    peak= cumret.cummax()\n",
        "    dd= (peak-cumret).max()\n",
        "    std_= rets.std()\n",
        "    sharpe= rets.mean()/std_*np.sqrt(365) if std_>1e-9 else 0.0\n",
        "    neg= rets[rets<0]\n",
        "    std_neg= neg.std()\n",
        "    sortino= rets.mean()/ (std_neg+1e-9)*np.sqrt(365) if std_neg>1e-9 else 0.0\n",
        "    gains= rets[rets>0].sum()\n",
        "    losses= abs(rets[rets<0].sum())\n",
        "    pf= (gains/losses) if losses>1e-9 else 999.0\n",
        "    return (sharpe, sortino, dd, pf)\n",
        "\n",
        "############################\n",
        "# 6) MAIN\n",
        "############################\n",
        "def main_csv_pipeline():\n",
        "    # 1) Descargar CSV\n",
        "    ok= download_csv_from_cryptodatadownload(CSV_URL, LOCAL_CSV)\n",
        "    if not ok:\n",
        "        print(\"No se pudo descargar CSV. Terminamos.\")\n",
        "        return\n",
        "\n",
        "    # 2) Leer CSV con skiprows=1\n",
        "    df_raw= pd.read_csv(LOCAL_CSV, skiprows=1)\n",
        "    # Renombrar columnas: \"date\"->\"Date\", \"Volume BTC\"->\"Volume\"\n",
        "    df_raw.rename(columns={\n",
        "        'date': 'Date',\n",
        "        'Volume BTC': 'Volume',   # CriptoDataDownload lo llama \"Volume BTC\"\n",
        "        'Volume USDT': 'VolumeUSDT'\n",
        "        }, inplace=True, errors='ignore')\n",
        "\n",
        "    # parse Date\n",
        "    df_raw['Date']= pd.to_datetime(df_raw['Date'])\n",
        "    df_raw.sort_values(by='Date', inplace=True)\n",
        "    df_raw.set_index('Date', inplace=True)\n",
        "\n",
        "    # Ver si \"Volume\" no existe pero \"VolumeUSDT\" existe\n",
        "    # a veces preferimos \"VolumeUSDT\" => rename => \"Volume\"\n",
        "    if \"Volume\" not in df_raw.columns and \"VolumeUSDT\" in df_raw.columns:\n",
        "        df_raw.rename(columns={\"VolumeUSDT\":\"Volume\"}, inplace=True)\n",
        "\n",
        "    # Aseguramos \"Open\",\"High\",\"Low\",\"Close\",\"Volume\"\n",
        "    needed= [\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]\n",
        "    missing= [c for c in needed if c not in df_raw.columns]\n",
        "    if missing:\n",
        "        print(f\"Falta col => {missing}. Revisa CSV de cryptodatadownload.\")\n",
        "        return\n",
        "\n",
        "    df = df_raw.copy()\n",
        "    df.dropna(subset=needed, inplace=True)\n",
        "    print(\"df shape tras parse:\", df.shape)\n",
        "    print(df.tail(5))\n",
        "\n",
        "    # 3) Indicadores\n",
        "    df['RSI14']= ta.rsi(df['Close'], length=14)\n",
        "    macd_= ta.macd(df['Close'], fast=12, slow=26)\n",
        "    df['MACD']= macd_['MACD_12_26_9']\n",
        "    df['MACDs']= macd_['MACDs_12_26_9']\n",
        "    df['EMA7']= ta.ema(df['Close'], length=7)\n",
        "    df['EMA21']= ta.ema(df['Close'], length=21)\n",
        "    bb= ta.bbands(df['Close'], length=20)\n",
        "    df['BBU']= bb['BBU_20_2.0']\n",
        "    df['BBM']= bb['BBM_20_2.0']\n",
        "    df['BBL']= bb['BBL_20_2.0']\n",
        "    stochrsi= ta.stochrsi(df['Close'], length=14)\n",
        "    df['STOCHRSIk']= stochrsi['STOCHRSIk_14_14_3_3']\n",
        "    df['STOCHRSId']= stochrsi['STOCHRSId_14_14_3_3']\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # ReturnFut\n",
        "    df['CloseShift']= df['Close'].shift(-1)\n",
        "    df['ReturnFut']= (df['CloseShift']- df['Close'])/df['Close']\n",
        "    df.dropna(inplace=True)\n",
        "\n",
        "    # y_bin => 1 si >= THRESHOLD_GAIN\n",
        "    df['y_bin']= (df['ReturnFut']>= THRESHOLD_GAIN).astype(int)\n",
        "\n",
        "    # 4) train vs test => ultima 60 dias\n",
        "    if len(df)< (TEST_DAYS+WINDOW+5):\n",
        "        print(\"No hay data suficiente post-limpieza.\")\n",
        "        return\n",
        "    df_train= df.iloc[:-TEST_DAYS].copy()\n",
        "    df_test = df.iloc[-TEST_DAYS:].copy()\n",
        "\n",
        "    feat_cols= [\n",
        "        \"Open\",\"High\",\"Low\",\"Close\",\"Volume\",\n",
        "        \"RSI14\",\"MACD\",\"MACDs\",\"EMA7\",\"EMA21\",\"BBU\",\"BBM\",\"BBL\",\"STOCHRSIk\",\"STOCHRSId\"\n",
        "    ]\n",
        "    df_train.dropna(subset=feat_cols, inplace=True)\n",
        "    df_test.dropna(subset=feat_cols, inplace=True)\n",
        "\n",
        "    # 5) Escalado\n",
        "    scaler= RobustScaler()\n",
        "    X_train_2D= scaler.fit_transform(df_train[feat_cols].values)\n",
        "    y_train_1D= df_train['y_bin'].values\n",
        "\n",
        "    def create_seq_bin(feat2D, targ1D, w):\n",
        "        X,y=[],[]\n",
        "        for i in range(len(feat2D)-w):\n",
        "            X.append(feat2D[i:i+w])\n",
        "            y.append(targ1D[i+w])\n",
        "        return np.array(X), np.array(y)\n",
        "\n",
        "    X_tr, y_tr= create_seq_bin(X_train_2D, y_train_1D, WINDOW)\n",
        "    if len(X_tr)<10:\n",
        "        print(\"Train no genera secuencias. Saliendo.\")\n",
        "        return\n",
        "\n",
        "    # 6) Modelo\n",
        "    model= Sequential([\n",
        "        LSTM(64, return_sequences=True, input_shape=(WINDOW,len(feat_cols))),\n",
        "        Dropout(0.3),\n",
        "        LSTM(32, return_sequences=False),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    opt= Adam(learning_rate=LR)\n",
        "    model.compile(optimizer=opt, loss=weighted_bce, metrics=['accuracy'])\n",
        "\n",
        "    # 80/20 split\n",
        "    val_size= int(len(X_tr)*0.2)\n",
        "    X_trn= X_tr[:-val_size]\n",
        "    y_trn= y_tr[:-val_size]\n",
        "    X_val= X_tr[-val_size:]\n",
        "    y_val= y_tr[-val_size:]\n",
        "\n",
        "    steps_per_epoch= len(X_trn)//BATCH_SIZE\n",
        "    if steps_per_epoch<1:\n",
        "        print(\"No hay data batch.\")\n",
        "        return\n",
        "\n",
        "    es= EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
        "    rlrop= ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=1, min_lr=1e-7)\n",
        "\n",
        "    print(f\"Entrenando con {len(X_trn)} (train) + {len(X_val)} (val).\")\n",
        "    model.fit(\n",
        "        X_trn, y_trn,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=EPOCHS,\n",
        "        batch_size=BATCH_SIZE,\n",
        "        callbacks=[es, rlrop],\n",
        "        shuffle=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # 7) test => mini-backtest\n",
        "    X_test_2D= scaler.transform(df_test[feat_cols].values)\n",
        "    y_test_1D= df_test['y_bin'].values\n",
        "    X_te, y_te= create_seq_bin(X_test_2D, y_test_1D, WINDOW)\n",
        "    if len(X_te)<1:\n",
        "        print(\"Test no genera secuencias. Saliendo.\")\n",
        "        return\n",
        "    df_test_seq= df_test.iloc[WINDOW:].copy()\n",
        "    df_test_seq= df_test_seq.iloc[: len(X_te)]\n",
        "    df_test_seq.reset_index(drop=False, inplace=True)\n",
        "\n",
        "    y_proba_test= model.predict(X_te).flatten()\n",
        "    y_bin_test= (y_proba_test>=0.5).astype(int)\n",
        "    df_test_seq['y_pred_bin']= y_bin_test\n",
        "    df_test_seq['OpenShift']= df_test_seq['Open'].shift(-1)\n",
        "    df_test_seq.dropna(inplace=True)\n",
        "\n",
        "    df_test_seq, daily_ret= backtest_binario(df_test_seq, STOP_LOSS, TAKE_PROFIT, COMMISSION)\n",
        "    final_pnl= df_test_seq['CumPnL'].iloc[-1]*100\n",
        "    sharpe_t, sortino_t, dd_t, pf_t= calc_metrics(daily_ret)\n",
        "    print(f\"\\n=== MINI-HOLDOUT => {len(df_test_seq)} muestras ===\")\n",
        "    print(f\"PNL= {final_pnl:.2f}%, Sharpe= {sharpe_t:.2f}, Sortino= {sortino_t:.2f}, DD= {dd_t:.2%}, PF= {pf_t:.2f}\")\n",
        "\n",
        "    # 8) Señal \"live\"\n",
        "    last_block= df.iloc[-WINDOW:].copy()\n",
        "    if len(last_block)< WINDOW:\n",
        "        print(\"No hay data live.\")\n",
        "        return\n",
        "    feat_live= last_block[feat_cols].values\n",
        "    feat_live_scaled= scaler.transform(feat_live)\n",
        "    X_live= np.expand_dims(feat_live_scaled, axis=0)\n",
        "    live_proba= model.predict(X_live).flatten()[0]\n",
        "    live_bin= 1 if live_proba>=0.5 else 0\n",
        "\n",
        "    last_dt= df.index[-1]\n",
        "    signal_str= \"BUY\" if live_bin==1 else \"NO_BUY\"\n",
        "    print(f\"Señal del día => {signal_str} (prob={live_proba:.4f})\")\n",
        "\n",
        "    row_save= {\n",
        "        \"datetime\": last_dt,\n",
        "        \"live_proba\": live_proba,\n",
        "        \"signal\": signal_str,\n",
        "        \"test_pnl\": final_pnl,\n",
        "        \"test_pf\": pf_t,\n",
        "        \"sharpe_test\": sharpe_t,\n",
        "        \"sortino_test\": sortino_t\n",
        "    }\n",
        "    df_save= pd.DataFrame([row_save])\n",
        "    if os.path.isfile(SAVE_TRADES_CSV):\n",
        "        df_save.to_csv(SAVE_TRADES_CSV, mode='a', header=False, index=False)\n",
        "    else:\n",
        "        df_save.to_csv(SAVE_TRADES_CSV, mode='w', header=True, index=False)\n",
        "\n",
        "    print(f\"Guardado en {SAVE_TRADES_CSV}\")\n",
        "    print(\"=== FIN DEL SCRIPT MAESTRO 13 (Descarga CSV + LSTM) ===\")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    main_csv_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pygfKjdMRJp",
        "outputId": "f8b7a4b2-7a70-4ee9-a23c-e2898ea35d43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Collecting pandas_ta\n",
            "  Downloading pandas_ta-0.3.14b.tar.gz (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.1/115.1 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from pandas_ta) (2.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->pandas_ta) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->pandas_ta) (1.17.0)\n",
            "Building wheels for collected packages: pandas_ta\n",
            "  Building wheel for pandas_ta (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandas_ta: filename=pandas_ta-0.3.14b0-py3-none-any.whl size=218909 sha256=4da94886d8b5d730db5a08d2eb359908cf298925fe31c62b6f4628c6233ea38d\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/33/8b/50b245c5c65433cd8f5cb24ac15d97e5a3db2d41a8b6ae957d\n",
            "Successfully built pandas_ta\n",
            "Installing collected packages: pandas_ta\n",
            "Successfully installed pandas_ta-0.3.14b0\n",
            "=== INICIO DEL SCRIPT MAESTRO 13 (Descarga CSV + Clasificación) ===\n",
            "Descargando CSV desde: https://www.cryptodatadownload.com/cdd/Binance_BTCUSDT_d.csv\n",
            "Guardado => /content/drive/MyDrive/Binance_BTCUSDT_daily.csv\n",
            "df shape tras parse: (2744, 9)\n",
            "                     Unix   Symbol      Open      High       Low     Close  \\\n",
            "Date                                                                         \n",
            "2025-02-15  1739577600000  BTCUSDT  97500.47  97972.26  97223.58  97569.66   \n",
            "2025-02-16  1739664000000  BTCUSDT  97569.67  97704.47  96046.18  96118.12   \n",
            "2025-02-17  1739750400000  BTCUSDT  96118.12  97046.59  95205.00  95780.00   \n",
            "2025-02-18  1739836800000  BTCUSDT  95780.01  96753.91  93388.09  95671.74   \n",
            "2025-02-19  1739923200000  BTCUSDT  95671.74  96899.99  95029.99  96644.37   \n",
            "\n",
            "                 Volume    VolumeUSDT  tradecount  \n",
            "Date                                               \n",
            "2025-02-15   7349.37683  7.172454e+08     1694327  \n",
            "2025-02-16   8191.42490  7.946942e+08     1596701  \n",
            "2025-02-17  16492.04510  1.584594e+09     2831237  \n",
            "2025-02-18  23368.19471  2.223995e+09     4234248  \n",
            "2025-02-19  16438.50954  1.576818e+09     2784225  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entrenando con 2096 (train) + 524 (val).\n",
            "Epoch 1/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 64ms/step - accuracy: 0.4847 - loss: 1.2928 - val_accuracy: 0.4828 - val_loss: 1.2494 - learning_rate: 1.0000e-04\n",
            "Epoch 2/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.4635 - loss: 1.2128 - val_accuracy: 0.4656 - val_loss: 1.1968 - learning_rate: 1.0000e-04\n",
            "Epoch 3/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.4735 - loss: 1.1594 - val_accuracy: 0.4332 - val_loss: 1.1586 - learning_rate: 1.0000e-04\n",
            "Epoch 4/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.4684 - loss: 1.1586 - val_accuracy: 0.4332 - val_loss: 1.1463 - learning_rate: 1.0000e-04\n",
            "Epoch 5/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.4689 - loss: 1.1520 - val_accuracy: 0.4332 - val_loss: 1.1439 - learning_rate: 1.0000e-04\n",
            "Epoch 6/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - accuracy: 0.4689 - loss: 1.1420 - val_accuracy: 0.4332 - val_loss: 1.1440 - learning_rate: 1.0000e-04\n",
            "Epoch 7/20\n",
            "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - accuracy: 0.4691 - loss: 1.1584 - val_accuracy: 0.4332 - val_loss: 1.1444 - learning_rate: 5.0000e-05\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 593ms/step\n",
            "\n",
            "=== MINI-HOLDOUT => 29 muestras ===\n",
            "PNL= -1.02%, Sharpe= -0.40, Sortino= -1.05, DD= 5.79%, PF= 0.90\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 597ms/step\n",
            "Señal del día => BUY (prob=0.7384)\n",
            "Guardado en /content/drive/MyDrive/Trading_Optimization_LSTM/paper_trades_binaria_diaria.csv\n",
            "=== FIN DEL SCRIPT MAESTRO 13 (Descarga CSV + LSTM) ===\n"
          ]
        }
      ]
    }
  ]
}